{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd113f77-e386-4517-8607-b64c76bdfe42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n",
      "Keras Version: 2.1.2\n",
      "Pandas Version: 1.1.5\n",
      "NumPy Version: 1.19.5\n",
      "OpenCV Version: 3.4.2\n"
     ]
    }
   ],
   "source": [
    "# NumPy, Pandas, Matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# TensorFlow와 Keras\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "\n",
    "\n",
    "# OpenCV (이미지 처리용)\n",
    "import cv2\n",
    "\n",
    "# Jupyter Notebook 환경에서 Matplotlib 인라인 설정\n",
    "%matplotlib inline\n",
    "\n",
    "# 확인용 버전 출력\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"OpenCV Version: {cv2.__version__}\")\n",
    "\n",
    "data_path = 'C:/Users/User/Desktop/Python/photofinder/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "922ed198-3154-496c-a2e1-78f88948dba1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8646, 160, 160, 3) (12843, 160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "correct_images = np.load(data_path + \"/array_ydata.npy\")  # 예: (n1, 160, 160, 3)\n",
    "incorrect_images = np.load(data_path + \"/array_ndata.npy\")  # 예: (n2, 160, 160, 3)\n",
    "print(correct_images.shape, incorrect_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6708d16f-091d-4e35-8c9e-25de8e53af68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "facenet_model = load_model(data_path + \"/facenet_keras.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fca8d7e8-8e9d-4b0b-9b68-6edbf1b943c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8646/8646 [==============================] - 178s 21ms/step\n",
      "Correct Embeddings Shape: (8646, 128)\n",
      "12843/12843 [==============================] - 271s 21ms/step\n",
      "Incorrect Embeddings Shape: (12843, 128)\n"
     ]
    }
   ],
   "source": [
    "# 정규화\n",
    "correct_images = correct_images.astype('float32') / 255.0\n",
    "incorrect_images = incorrect_images.astype('float32') / 255.0\n",
    "\n",
    "# 정답 이미지를 FaceNet에 입력하여 임베딩 생성\n",
    "correct_embeddings = facenet_model.predict(correct_images, verbose=1)\n",
    "print(f\"Correct Embeddings Shape: {correct_embeddings.shape}\")  # (n1, 128)\n",
    "\n",
    "# 오답 이미지를 FaceNet에 입력하여 임베딩 생성\n",
    "incorrect_embeddings = facenet_model.predict(incorrect_images, verbose=1)\n",
    "print(f\"Incorrect Embeddings Shape: {incorrect_embeddings.shape}\")  # (n2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01cc4eda-eed7-4fc9-a332-06ea5646198d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(data_path + '/emb_ydata.npy', correct_embeddings)\n",
    "np.save(data_path + '/emb_ndata.npy', incorrect_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4d70921-9e4f-4516-826e-c2e451a15ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8646, 128) (12843, 128)\n",
      "(8646,) (12843,)\n",
      "(21489, 128) (21489,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b5cbbd1233fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# TensorFlow 데이터셋 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 셔플\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# =======[재현]=======\n",
    "\n",
    "correct_emb = np.load(data_path + '/emb_ydata.npy')\n",
    "incorrect_emb = np.load(data_path + '/emb_ndata.npy')\n",
    "\n",
    "print(correct_emb.shape, incorrect_emb.shape)\n",
    "\n",
    "labels_truth = np.ones((correct_emb.shape[0],), dtype='float32')  # 진실 → 1\n",
    "labels_false = np.zeros((incorrect_emb.shape[0],), dtype='float32')  # 거짓 → 0\n",
    "\n",
    "print(labels_truth.shape, labels_false.shape)\n",
    "\n",
    "X = np.vstack((correct_emb, incorrect_emb))  # 입력 데이터 병합\n",
    "y = np.hstack((labels_truth, labels_false))        # 레이블 병합\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# TensorFlow 데이터셋 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "dataset = dataset.shuffle(buffer_size=len(X), seed=42) # 셔플\n",
    "\n",
    "# 학습/테스트 데이터 분할 (7:3 비율)\n",
    "train_size = int(len(X) * 0.7)\n",
    "train_dataset = dataset.take(train_size)\n",
    "test_dataset = dataset.skip(train_size)\n",
    "\n",
    "print(f\"Train Dataset: {train_dataset}\")\n",
    "print(f\"Test Dataset: {test_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab72a86f-b80a-4fa9-8d62-36f17f0b17e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow' from 'C:\\\\Users\\\\User\\\\anaconda3\\\\envs\\\\facenet\\\\lib\\\\site-packages\\\\tensorflow\\\\__init__.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5e26a-3612-4f42-a225-b0b5b80f477c",
   "metadata": {},
   "source": [
    "# 테스트에 사용된 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2723ee5-835a-4e1c-bdc7-a30f2ee78527",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\facenet\\lib\\site-packages\\keras\\models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# NumPy, Pandas, Matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# TensorFlow와 Keras\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "\n",
    "data_path = 'C:/Users/User/Desktop/Python/photofinder/data'\n",
    "facenet_model = load_model(data_path + \"/facenet_keras.h5\")\n",
    "tester = np.load(\"C:\\\\Users\\\\User\\\\Desktop\\\\Python\\\\photofinder\\\\data/test_datas/processed_images.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d82bf72f-4864-41af-a182-ee6615e79a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 128)\n"
     ]
    }
   ],
   "source": [
    "embedding_array = facenet_model.predict(tester)\n",
    "print(embedding_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbac721d-fd5b-486e-989f-c82d6fe99cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"C:\\\\Users\\\\User\\\\Desktop\\\\Python\\\\photofinder\\\\data/test_datas/emb_array.npy\", embedding_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facenet",
   "language": "python",
   "name": "facenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
